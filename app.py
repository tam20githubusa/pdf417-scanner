# -*- coding: utf-8 -*-
import streamlit as st
import cv2
import zxingcpp
import numpy as np
import pandas as pd
import math
from PIL import Image

# ==================== 0. é¡µé¢é…ç½®ä¸ CSS æ ·å¼ä¼˜åŒ– ====================

st.set_page_config(page_title="PDF417 æ‰«ç ä¸“å®¶", page_icon="ğŸ’³", layout="wide")

# æ³¨å…¥ CSSï¼šå¼ºåˆ¶å»é™¤è¾¹è·ï¼Œæ”¾å¤§ç›¸æœºï¼Œä¼˜åŒ–æç¤ºæ¡†
st.markdown("""
    <style>
        /* 1. æå¤§å¹…åº¦å‡å°‘é¡µé¢å››å‘¨çš„ç•™ç™½ */
        .block-container {
            padding: 1rem 0.5rem;
        }
        
        /* 2. å¼ºåˆ¶ç½‘é¡µç›¸æœºç»„ä»¶å æ»¡ 100% å®½åº¦ */
        div[data-testid="stCameraInput"] {
            width: 100% !important;
        }
        div[data-testid="stCameraInput"] video {
            border-radius: 12px !important;
            width: 100% !important;
            object-fit: cover;
        }

        /* 3. åŠ å¤§ Tab æ ‡ç­¾æ–‡å­—ï¼Œæ›´å®¹æ˜“ç‚¹ */
        button[data-baseweb="tab"] div {
            font-size: 1.1em !important;
            padding: 1em !important;
        }
    </style>
""", unsafe_allow_html=True)

# ==================== 1. æ ¸å¿ƒç®—æ³•åŒº ====================

def get_hex_dump_str(raw_bytes):
    """ç”Ÿæˆæ˜“è¯»çš„ HEX æ•°æ®è§†å›¾"""
    output = []
    output.append(f"ğŸ“¦ æ•°æ®é•¿åº¦: {len(raw_bytes)} å­—èŠ‚")
    output.append("-" * 50)
    
    try:
        hex_str = raw_bytes.hex().upper()
    except AttributeError:
        # å¦‚æœ zxingcpp è¿”å›çš„æ˜¯ text (str)ï¼Œåˆ™éœ€è¦å…ˆç¼–ç ä¸º bytes
        hex_str = raw_bytes.encode('utf-8').hex().upper()

    for i in range(0, len(hex_str), 32):
        chunk = hex_str[i:i+32]
        ascii_chunk = ""
        for j in range(0, len(chunk), 2):
            try:
                byte_val = int(chunk[j:j+2], 16)
                ascii_chunk += chr(byte_val) if 32 <= byte_val <= 126 else "."
            except ValueError:
                ascii_chunk += "?" # å¤„ç†æœ«å°¾ä¸å®Œæ•´çš„å­—èŠ‚
        output.append(f"{chunk.ljust(32)} | {ascii_chunk}")
    return "\n".join(output)

def preprocess_image_candidates(img):
    """ç”Ÿæˆå›¾åƒå€™é€‰é¡¹"""
    candidates = []
    candidates.append(("åŸå›¾", img))
    
    # è½¬æ¢ä¸ºç°åº¦å›¾ (zxingcpp éœ€è¦)
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img
        
    # ç»å…¸å¢å¼ºç®—æ³•
    candidates.append(("ç°åº¦", gray))
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    candidates.append(("CLAHE", enhanced)) # å±€éƒ¨å¯¹æ¯”åº¦å¢å¼º
    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])
    sharpened = cv2.filter2D(enhanced, -1, kernel)
    candidates.append(("é”åŒ–", sharpened)) # é”åŒ–
    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    candidates.append(("äºŒå€¼(OTSU)", binary)) # å¤§æ´¥äºŒå€¼åŒ–
    return candidates

def try_decode(image):
    """å°è¯•è§£ç """
    try:
        results = zxingcpp.read_barcodes(image)
        for result in results:
            if result.format == zxingcpp.BarcodeFormat.PDF417:
                return True, result
    except Exception:
        pass
    return False, None

def smart_scan_logic(original_img):
    """æ™ºèƒ½æ‰«æä¸»é€»è¾‘ (HAX å¢å¼ºç‰ˆ)"""
    base_candidates = preprocess_image_candidates(original_img)
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_steps = len(base_candidates) * 4
    step = 0
    found_result = None

    for mode_name, img_candidate in base_candidates:
        # å¸¸è§æ¡ç æ–¹å‘å’Œå¯†åº¦é—®é¢˜
        transforms = [
            ("æ­£å¸¸", lambda x: x),
            ("æ—‹è½¬90Â°", lambda x: cv2.rotate(x, cv2.ROTATE_90_CLOCKWISE)),
            ("æ”¾å¤§1.5x", lambda x: cv2.resize(x, None, fx=1.5, fy=1.5)),
            # ("ç¼©å°0.5x", lambda x: cv2.resize(x, (x.shape[1]//2, x.shape[0]//2))) 
        ]
        
        for trans_name, trans_func in transforms:
            step += 1
            progress_bar.progress(min(step / total_steps, 0.95))
            status_text.caption(f"æ­£åœ¨åˆ†æ: {mode_name} / {trans_name}...")
            
            try:
                processed_img = trans_func(img_candidate)
                success, result = try_decode(processed_img)
                if success:
                    found_result = result
                    status_text.success(f"âœ… è¯†åˆ«æˆåŠŸ! (æ¨¡å¼: {mode_name} - {trans_name})")
                    progress_bar.progress(1.0)
                    break
            except Exception:
                 continue
        
        if found_result: break
            
    if not found_result:
        status_text.error("âŒ æœªè¯†åˆ«ã€‚è¯·é è¿‘ä¸€ç‚¹ï¼Œç¡®ä¿å…‰çº¿å……è¶³ä¸”å¯¹ç„¦æ¸…æ™°ã€‚")
        progress_bar.empty()
    return found_result

# --- æ–°å¢ï¼šPDF417 å‚æ•°é€†å‘è®¡ç®— ---

def calculate_pdf417_params(byte_len):
    """
    æ ¹æ®å­—èŠ‚é•¿åº¦ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½çš„ PDF417 è¡Œåˆ—ç»„åˆï¼Œå¹¶ä¼°ç®—å®½é«˜æ¯”ã€‚
    """
    if byte_len <= 0:
        return pd.DataFrame()

    estimated_data_cw = math.ceil(byte_len / 1.8) 
    ecc_cw = 64  # Level 5 Security (AAMVA Standard)
    total_cw = estimated_data_cw + ecc_cw
    
    data = []
    possible_cols = range(9, 21)
    
    for cols in possible_cols:
        rows = math.ceil(total_cw / cols)
        
        if rows < 3 or rows > 90:
            continue
            
        width_units = (cols + 4) * 17
        height_units = rows * 3 
        ratio = width_units / height_units

        note = ""
        if cols == 17: note = "â­ AAMVA æ ‡å‡†"
        elif 11 <= cols <= 13: note = "ğŸ”¹ çª„ç‰ˆ (NY/CAé£æ ¼)"
        
        if 3.0 <= ratio <= 5.0: note += " | å®Œç¾æ¯”ä¾‹"
        elif ratio > 6.0: note += " | æ‰é•¿æ¡ç "
        elif ratio < 2.5: note += " | æ­£æ–¹æ¡ç "
        
        data.append({
            "åˆ—æ•° (Cols)": cols,
            "æ¨ç®—è¡Œæ•° (Rows)": rows,
            "ä¼°ç®—å®½é«˜æ¯” (W/H)": f"{ratio:.1f}",
            "ç±»å‹å¤‡æ³¨": note
        })
    
    return pd.DataFrame(data)

# --- æ–°å¢ï¼šAAMVA æ•°æ®è§£æå‡½æ•° ---

def parse_aamva_data(raw_bytes):
    """
    è§£æ AAMVA D20 æ ‡å‡†çš„åŸå§‹å­—èŠ‚æ•°æ®ï¼Œæå–å…³é”®å­—æ®µã€‚
    """
    try:
        # AAMVA ä½¿ç”¨ ASCII æˆ– Latin-1 ç¼–ç 
        data_str = raw_bytes.decode('latin-1', errors='ignore') 
    except Exception:
        return {"Error": "æ— æ³•å°†æ•°æ®è§£ç ä¸º ASCII/Latin-1 æ–‡æœ¬ã€‚"}

    # å®šä¹‰å­—æ®µåˆ†éš”ç¬¦ (RS: 1E) å’Œè®°å½•åˆ†éš”ç¬¦ (LF: 0A, CR: 0D)
    
    # æŸ¥æ‰¾ä¸»æ•°æ®æ®µ (ä»¥ DL, ID, æˆ– DB å¼€å¤´)
    segments = data_str.split('\x1e') 
    
    # å­—æ®µä»£ç åˆ°æè¿°çš„æ˜ å°„ (åªåˆ—å‡ºå…³é”®å­—æ®µå’Œæ‚¨æåˆ°çš„å­—æ®µ)
    fields_map = {
        "DCS": "å§“æ° (Last Name)",
        "DDEN": "å (First Name)",
        "DAC": "ä¸­é—´å (Middle Name)",
        "DDG": "ç­¾å‘æ—¥æœŸ (Issue Date)",
        "DBD": "å‡ºç”Ÿæ—¥æœŸ (DOB)",
        "DBA": "åˆ°æœŸæ—¥æœŸ (Expiry Date)",
        "DCD": "é©¾ç…§/è¯ä»¶å·ç  (License No.)", # å…³é”®å­—æ®µ
        "DBC": "æ€§åˆ« (Gender Code)",
        "DAU": "åœ°å€ (Street)",
        "DAI": "åŸå¸‚ (City)",
        "DAJ": "å·/çœ (Jurisdiction)",
        "DCF": "å›½å®¶/åœ°åŒº (Country)",
        "DCK": "èº«é«˜/ä½“é‡ (CK)",
        # ZFZFA - ZFK æ˜¯å·è‡ªå®šä¹‰å­—æ®µï¼Œé€šå¸¸ç”¨äºå†—ä½™æ•°æ®
        "ZFJ": "è‡ªå®šä¹‰å· (ZFJ)"
    }
    
    parsed_data = {}
    
    # æŸ¥æ‰¾ä¸»æ•°æ®æ®µ
    main_segment_found = False
    for segment in segments:
        if segment.startswith('DL') or segment.startswith('ID'):
            main_segment_found = True
            data_content = segment[segment.find('Z')+1:] # ä» 'Z' ä¹‹åå¼€å§‹è§£ææ•°æ®
            break
            
    if not main_segment_found:
        return {"Error": "æœªæ‰¾åˆ° DL/ID ä¸»æ•°æ®æ®µã€‚"}
        
    # è§£æé€»è¾‘ï¼šå¯»æ‰¾ 3 æˆ– 4 ä¸ªå¤§å†™å­—æ¯çš„ä»£ç 
    current_pos = 0
    while current_pos < len(data_content):
        match_found = False
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå­—æ®µä»£ç ï¼ˆ3æˆ–4ä¸ªå¤§å†™å­—æ¯ï¼‰
        for code in fields_map.keys():
            if data_content.startswith(code, current_pos):
                field_code = code
                field_description = fields_map[field_code]
                
                # å¯»æ‰¾ä¸‹ä¸€ä¸ªå­—æ®µä»£ç çš„èµ·å§‹ä½ç½®ä½œä¸ºå½“å‰å€¼çš„ç»“æŸ
                next_field_pos = len(data_content)
                
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå­—æ®µä»£ç çš„ä½ç½® (å¯ä»¥æ˜¯ä»»ä½•ä¸€ä¸ªå·²çŸ¥çš„ä»£ç )
                for next_code in fields_map.keys():
                    pos = data_content.find(next_code, current_pos + len(field_code))
                    if pos != -1 and pos < next_field_pos:
                         next_field_pos = pos
                
                value = data_content[current_pos + len(field_code): next_field_pos]
                
                # æ¸…ç†å€¼ä¸­çš„åˆ†éš”ç¬¦ (\n, \r)
                parsed_data[field_description] = value.replace('\n', '').replace('\r', '').strip()
                current_pos = next_field_pos
                match_found = True
                break
        
        if not match_found:
            current_pos += 1 # æ‰¾ä¸åˆ°å­—æ®µæ—¶è·³è¿‡ï¼Œé¿å…æ­»å¾ªç¯
        
        if current_pos >= len(data_content):
            break
            
    return parsed_data

# ==================== 2. ç½‘é¡µç•Œé¢åŒº ====================

st.title("ğŸ’³ PDF417 æ‰«ç ä¸“å®¶")

# ä½¿ç”¨ tabs è¿›è¡Œæ¨¡å¼åˆ‡æ¢
tab1, tab2 = st.tabs(["ğŸ“¸ ç½‘é¡µå°çª— (å¿«é€Ÿ)", "ğŸ“± å…¨å±æ‹ç…§ (é«˜æ¸…æ¨è)"])

target_image = None
raw_data = None
data_source = None

# --- Tab 1: ç½‘é¡µç›¸æœº ---
with tab1:
    st.caption("é€‚ç”¨äºå…‰çº¿å¥½ã€æ¡ç æ¸…æ™°çš„ç®€å•åœºæ™¯ã€‚è¯·æ¨ªå±ä½¿ç”¨ã€‚")
    camera_file = st.camera_input("è¯·å¯¹å‡†æ¡ç ", label_visibility="collapsed")
    if camera_file:
        file_bytes = np.asarray(bytearray(camera_file.read()), dtype=np.uint8)
        target_image = cv2.imdecode(file_bytes, 1)
        data_source = "ç½‘é¡µç›¸æœº"

# --- Tab 2: å…¨å±æ‹ç…§ (æ ¸å¿ƒä¿®æ”¹ç‚¹) ---
with tab2:
    st.markdown("""
        <div style="background-color: #e8f5e9; padding: 15px; border-radius: 10px; border-left: 5px solid #4caf50; margin-bottom: 20px;">
            <h4 style="margin: 0; color: #2e7d32; font-size: 1.1rem;">ğŸš€ æœ€ä½³è¯†åˆ«æ–¹æ¡ˆï¼š</h4>
            <p style="margin: 10px 0 0 0; font-size: 1rem; color: #333;">
                ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œåœ¨å¼¹å‡ºçš„èœå•ä¸­é€‰æ‹© <b>â€œæ‹ç…§â€</b> æˆ– <b>â€œç›¸æœºâ€</b>ã€‚<br>
                è¿™å°†å¯åŠ¨ä½ çš„<b>ç³»ç»ŸåŸç”Ÿç›¸æœº</b>ï¼Œäº«å—<b>å…¨å±ã€é«˜æ¸…ã€æ‰‹åŠ¨å¯¹ç„¦</b>ä½“éªŒï¼
            </p>
        </div>
    """, unsafe_allow_html=True)

    upload_file = st.file_uploader("å¯åŠ¨å…¨å±ç›¸æœº", type=["jpg", "png", "jpeg", "heic"], label_visibility="collapsed")
    
    if upload_file:
        with st.spinner("æ­£åœ¨ä¸Šä¼ é«˜æ¸…åŸå›¾å¹¶è§£ç ..."):
            file_bytes = np.asarray(bytearray(upload_file.read()), dtype=np.uint8)
            target_image = cv2.imdecode(file_bytes, 1)
            data_source = "æ–‡ä»¶ä¸Šä¼ "

# --- å¤„ç†ç»“æœå±•ç¤º ---
if target_image is not None:
    st.divider()
    result = smart_scan_logic(target_image)
    
    if result:
        st.success("ğŸ‰ è§£ç æˆåŠŸï¼")
        raw_data = result.bytes if result.bytes else result.text.encode('latin-1', errors='ignore')
        
        # ç¡®å®šæ•°æ®ç±»å‹
        data_type = "äºŒè¿›åˆ¶ (Bytes)" if isinstance(result.bytes, bytes) else "æ–‡æœ¬ (Text)"
        
        # 1. ç»“æœæ¦‚è§ˆ
        st.info(f"æ•°æ®ç±»å‹: **{data_type}** | å­—èŠ‚é•¿åº¦: **{len(raw_data)}** bytes")
        
        # 2. ç»“æ„åŒ–è§£æ (æ–°å¢åŒºåŸŸ)
        if data_type == "äºŒè¿›åˆ¶ (Bytes)" and len(raw_data) > 100:
            st.subheader("ğŸ“‹ ç»“æ„åŒ–æ•°æ®è§£æ (AAMVA)")
            parsed_data = parse_aamva_data(raw_data)
            
            if "Error" in parsed_data:
                 st.error(f"è§£æå¤±è´¥: {parsed_data['Error']}")
            else:
                 # ä½¿ç”¨ Pandas DataFrame å±•ç¤ºè§£æç»“æœï¼Œæ›´ç¾è§‚
                 df_parsed = pd.DataFrame(parsed_data.items(), columns=["å­—æ®µ", "å€¼"])
                 
                 # ç¡®ä¿è®¸å¯è¯å·å’Œå§“åæ”¾åœ¨æœ€å‰é¢
                 df_parsed = df_parsed.sort_values(by="å­—æ®µ", key=lambda x: x.map({'é©¾ç…§/è¯ä»¶å·ç  (License No.)': 0, 'å§“æ° (Last Name)': 1}), ascending=True, ignore_index=True)
                 
                 st.dataframe(df_parsed, use_container_width=True, hide_index=True)
                 
                 # --- æ¼”ç¤ºæ‚¨æƒ³è¦çš„æ ¼å¼ (DAQ123456 é©¾ç…§/èº«ä»½è¯å· 123456) ---
                 license_no = parsed_data.get('é©¾ç…§/è¯ä»¶å·ç  (License No.)', 'N/A')
                 st.markdown(f"**å¿«é€ŸæŸ¥çœ‹:** **{license_no}** å¯¹åº” **é©¾ç…§/è¯ä»¶å·ç **")

        # 3. HEX æ•°æ®
        with st.expander("æŸ¥çœ‹åº•å±‚ HEX æ•°æ® (ç‚¹å‡»å±•å¼€)", expanded=False):
            hex_str = get_hex_dump_str(raw_data)
            st.code(hex_str, language="text")

        # 4. å‚æ•°é€†å‘è®¡ç®—å™¨ (å«å¯¼å‡º CSV)
        st.subheader("ğŸ“ PDF417 å‚æ•°é€†å‘è®¡ç®— (AAMVA)")
        byte_len = len(raw_data)
        df_params = calculate_pdf417_params(byte_len)
        
        col_summary, col_table_content = st.columns([1, 2])

        with col_summary:
            st.markdown(f"**åˆ†æé•¿åº¦:** `{byte_len} bytes`")
            st.markdown(f"**ECC å®‰å…¨ç­‰çº§:** `Level 5 (64 Codewords)`")
            
            best_row = df_params[df_params['åˆ—æ•° (Cols)'] == 17]
            if not best_row.empty:
                rec_rows = best_row.iloc[0]['æ¨ç®—è¡Œæ•° (Rows)']
                st.success(f"ğŸ’¡ AAMVA æ¨è: **Cols=17, Rows={rec_rows}**")

        with col_table_content:
            col_header, col_button = st.columns([4, 1])
            
            with col_header:
                st.markdown("##### æ¨ç®—è¡Œåˆ—ç»„åˆç»“æœ (æ•°æ®è¡¨)")

            with col_button:
                csv_data = df_params.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ’¾ å¯¼å‡º CSV",
                    data=csv_data,
                    file_name='pdf417_params.csv',
                    mime='text/csv',
                    help="ç‚¹å‡»ä¸‹è½½è¡¨æ ¼æ•°æ®ä¸º CSV æ–‡ä»¶ï¼Œæ–¹ä¾¿å¤åˆ¶åˆ°å…¶ä»–åœ°æ–¹ã€‚"
                )
            
            st.dataframe(
                df_params,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "ä¼°ç®—å®½é«˜æ¯” (W/H)": st.column_config.TextColumn("W/H æ¯”ä¾‹"),
                    "ç±»å‹å¤‡æ³¨": st.column_config.TextColumn("å¤‡æ³¨"),
                }
            )

        # 5. é‡å¼€æŒ‰é’®
        st.divider()
        if st.button("ğŸ”„ æ‰«æä¸‹ä¸€å¼ ", type="primary"):
            st.rerun()
