# -*- coding: utf-8 -*-
import streamlit as st
import cv2
import zxingcpp
import numpy as np
import pandas as pd
import math
from PIL import Image

# ==================== 0. é¡µé¢é…ç½®ä¸ CSS æ ·å¼ä¼˜åŒ– ====================

st.set_page_config(page_title="PDF417 æ‰«ç ä¸“å®¶", page_icon="ğŸ’³", layout="wide")

# æ³¨å…¥ CSSï¼šå¼ºåˆ¶å»é™¤è¾¹è·ï¼Œæ”¾å¤§ç›¸æœºï¼Œä¼˜åŒ–æç¤ºæ¡†
st.markdown("""
    <style>
        /* 1. æå¤§å¹…åº¦å‡å°‘é¡µé¢å››å‘¨çš„ç•™ç™½ */
        .block-container {
            padding: 1rem 0.5rem;
        }
        
        /* 2. å¼ºåˆ¶ç½‘é¡µç›¸æœºç»„ä»¶å æ»¡ 100% å®½åº¦ */
        div[data-testid="stCameraInput"] {
            width: 100% !important;
        }
        div[data-testid="stCameraInput"] video {
            border-radius: 12px !important;
            width: 100% !important;
            object-fit: cover;
        }

        /* 3. åŠ å¤§ Tab æ ‡ç­¾æ–‡å­—ï¼Œæ›´å®¹æ˜“ç‚¹ */
        button[data-baseweb="tab"] div {
            font-size: 1.1em !important;
            padding: 1em !important;
        }
    </style>
""", unsafe_allow_html=True)

# ==================== 1. æ ¸å¿ƒç®—æ³•åŒº ====================

def get_hex_dump_str(raw_bytes):
    """ç”Ÿæˆæ˜“è¯»çš„ HEX æ•°æ®è§†å›¾"""
    output = []
    output.append(f"ğŸ“¦ æ•°æ®é•¿åº¦: {len(raw_bytes)} å­—èŠ‚")
    output.append("-" * 50)
    
    try:
        hex_str = raw_bytes.hex().upper()
    except AttributeError:
        # å¦‚æœ zxingcpp è¿”å›çš„æ˜¯ text (str)ï¼Œåˆ™éœ€è¦å…ˆç¼–ç ä¸º bytes
        hex_str = raw_bytes.encode('utf-8').hex().upper()

    for i in range(0, len(hex_str), 32):
        chunk = hex_str[i:i+32]
        ascii_chunk = ""
        for j in range(0, len(chunk), 2):
            try:
                byte_val = int(chunk[j:j+2], 16)
                # ä½¿ç”¨ chr() ç¡®ä¿åªæ˜¾ç¤ºå¯æ‰“å°å­—ç¬¦
                ascii_chunk += chr(byte_val) if 32 <= byte_val <= 126 else "." 
            except ValueError:
                ascii_chunk += "?" # å¤„ç†æœ«å°¾ä¸å®Œæ•´çš„å­—èŠ‚
        output.append(f"{chunk.ljust(32)} | {ascii_chunk}")
    return "\n".join(output)

def preprocess_image_candidates(img):
    """ç”Ÿæˆå›¾åƒå€™é€‰é¡¹"""
    candidates = []
    candidates.append(("åŸå›¾", img))
    
    # è½¬æ¢ä¸ºç°åº¦å›¾ (zxingcpp éœ€è¦)
    if len(img.shape) == 3:
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        gray = img
        
    # ç»å…¸å¢å¼ºç®—æ³•
    candidates.append(("ç°åº¦", gray))
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    candidates.append(("CLAHE", enhanced)) # å±€éƒ¨å¯¹æ¯”åº¦å¢å¼º
    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])
    sharpened = cv2.filter2D(enhanced, -1, kernel)
    candidates.append(("é”åŒ–", sharpened)) # é”åŒ–
    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    candidates.append(("äºŒå€¼(OTSU)", binary)) # å¤§æ´¥äºŒå€¼åŒ–
    return candidates

def try_decode(image):
    """å°è¯•è§£ç """
    try:
        results = zxingcpp.read_barcodes(image)
        for result in results:
            if result.format == zxingcpp.BarcodeFormat.PDF417:
                return True, result
    except Exception:
        pass
    return False, None

def smart_scan_logic(original_img):
    """æ™ºèƒ½æ‰«æä¸»é€»è¾‘ (HAX å¢å¼ºç‰ˆ)"""
    base_candidates = preprocess_image_candidates(original_img)
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_steps = len(base_candidates) * 4
    step = 0
    found_result = None

    for mode_name, img_candidate in base_candidates:
        # å¸¸è§æ¡ç æ–¹å‘å’Œå¯†åº¦é—®é¢˜
        transforms = [
            ("æ­£å¸¸", lambda x: x),
            ("æ—‹è½¬90Â°", lambda x: cv2.rotate(x, cv2.ROTATE_90_CLOCKWISE)),
            ("æ”¾å¤§1.5x", lambda x: cv2.resize(x, None, fx=1.5, fy=1.5)),
        ]
        
        for trans_name, trans_func in transforms:
            step += 1
            progress_bar.progress(min(step / total_steps, 0.95))
            status_text.caption(f"æ­£åœ¨åˆ†æ: {mode_name} / {trans_name}...")
            
            try:
                processed_img = trans_func(img_candidate)
                success, result = try_decode(processed_img)
                if success:
                    found_result = result
                    status_text.success(f"âœ… è¯†åˆ«æˆåŠŸ! (æ¨¡å¼: {mode_name} - {trans_name})")
                    progress_bar.progress(1.0)
                    break
            except Exception:
                 continue
        
        if found_result: break
            
    if not found_result:
        status_text.error("âŒ æœªè¯†åˆ«ã€‚è¯·é è¿‘ä¸€ç‚¹ï¼Œç¡®ä¿å…‰çº¿å……è¶³ä¸”å¯¹ç„¦æ¸…æ™°ã€‚")
        progress_bar.empty()
    return found_result

# --- PDF417 å‚æ•°é€†å‘è®¡ç®— ---

def calculate_pdf417_params(byte_len):
    """
    æ ¹æ®å­—èŠ‚é•¿åº¦ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½çš„ PDF417 è¡Œåˆ—ç»„åˆï¼Œå¹¶ä¼°ç®—å®½é«˜æ¯”ã€‚
    """
    if byte_len <= 0:
        return pd.DataFrame()

    estimated_data_cw = math.ceil(byte_len / 1.8) 
    ecc_cw = 64  # Level 5 Security (AAMVA Standard)
    total_cw = estimated_data_cw + ecc_cw
    
    data = []
    possible_cols = range(9, 21)
    
    for cols in possible_cols:
        rows = math.ceil(total_cw / cols)
        
        if rows < 3 or rows > 90:
            continue
            
        width_units = (cols + 4) * 17
        height_units = rows * 3 
        ratio = width_units / height_units

        note = ""
        if cols == 17: note = "â­ AAMVA æ ‡å‡†"
        elif 11 <= cols <= 13: note = "ğŸ”¹ çª„ç‰ˆ (NY/CAé£æ ¼)"
        
        if 3.0 <= ratio <= 5.0: note += " | å®Œç¾æ¯”ä¾‹"
        elif ratio > 6.0: note += " | æ‰é•¿æ¡ç "
        elif ratio < 2.5: note += " | æ­£æ–¹æ¡ç "
        
        data.append({
            "åˆ—æ•° (Cols)": cols,
            "æ¨ç®—è¡Œæ•° (Rows)": rows,
            "ä¼°ç®—å®½é«˜æ¯” (W/H)": f"{ratio:.1f}",
            "ç±»å‹å¤‡æ³¨": note
        })
    
    return pd.DataFrame(data)

# --- AAMVA æ•°æ®è§£æå‡½æ•° (æœ€ç»ˆä¿®å¤ç‰ˆ) ---

def parse_aamva_data(raw_bytes):
    """
    è§£æ AAMVA D20 æ ‡å‡†çš„åŸå§‹å­—èŠ‚æ•°æ®ï¼Œæå–å…³é”®å­—æ®µã€‚
    ã€æœ€ç»ˆä¿®å¤ï¼šé‡‡ç”¨ç²¾å‡†ä½ç½®åˆ‡ç‰‡ (Slicing) æ–¹æ³•ï¼ŒåŸºäºæ‰€æœ‰å­—æ®µä»£ç çš„èµ·å§‹ä½ç½®æ¥åˆ†å‰²æ•°æ®ã€‚ã€‘
    """
    try:
        # AAMVA é€šå¸¸ä½¿ç”¨ ASCII æˆ– Latin-1 ç¼–ç 
        data_str = raw_bytes.decode('latin-1', errors='ignore') 
    except Exception:
        return {"Error": "æ— æ³•å°†æ•°æ®è§£ç ä¸º ASCII/Latin-1 æ–‡æœ¬ã€‚"}

    # 1. å®šä¹‰ç»¼åˆå­—æ®µä»£ç æ˜ å°„ (æ›´å‡†ç¡®çš„ AAMVA D20 2020/2022 æ ‡å‡†åˆ—è¡¨)
    fields_map = {
        # ID/Name Fields
        "DCS": "å§“æ° (Last Name)",
        "DAC": "å (First Name)",
        "DAD": "ä¸­é—´å (Middle Name)",
        # Date Fields (4-char codes are typically dates/status)
        "DBB": "å‡ºç”Ÿæ—¥æœŸ (DOB)",
        "DBA": "åˆ°æœŸæ—¥æœŸ (Expiry Date)",
        "DBD": "ç­¾å‘æ—¥æœŸ (Issue Date)",
        # Identification/Control Fields
        "DAQ": "é©¾ç…§/è¯ä»¶å·ç  (License No.)", 
        "DCF": "æ¡£æ¡ˆç¼–å·/é‰´åˆ«ç  (DD)",
        "DCK": "åº“å­˜æ§åˆ¶å· (ICN)",
        "DCG": "å›½ç± (Nationality)",
        # Physical/Demographic
        "DBC": "æ€§åˆ« (Gender Code)",
        "DAU": "èº«é«˜ (Height)",
        "DAW": "ä½“é‡ (Weight)",
        "DAY": "çœ¼ç›é¢œè‰² (Eye Color)",
        "DAZ": "å¤´å‘é¢œè‰² (Hair Color)",
        # Address
        "DAG": "åœ°å€ (Street)",
        "DAI": "åŸå¸‚ (City)",
        "DAJ": "å·/çœ (State)",
        "DAK": "é‚®ç¼– (ZIP)",
        # License Info
        "DCA": "é©¾ç…§çº§åˆ« (CLASS)",
        "DCB": "é©¾ç…§é™åˆ¶ (REST)",
        "DCD": "é©¾ç…§èƒŒä¹¦ (END)",
        "DDB": "è¯¥ç‰ˆé¢é©¾ç…§çš„å‘è¡Œæ—¥æœŸ (REV)", # ç­¾å‘äºº/æœºæ„
        # Donation/Veteran
        "DDL": "æœå½¹å†›äºº",
        "DDK": "å™¨å®˜æçŒ®è€…",
        # Other
        "ZFJ": " å®¡è®¡ä¿¡æ¯(Audit info)",
        "ZFC": "å®‰å…¨é©¾é©¶ (SAFE DRIVER)",
    }
    
    parsed_data = {}
    
    # 2. æŸ¥æ‰¾ä¸»æ•°æ®æ®µ (ä»¥ DL æˆ– ID å¼€å¤´)
    segments = data_str.split('\x1e') # ä½¿ç”¨ Record Separator (\x1e) åˆ†å‰²æ‰€æœ‰æ®µè½
    main_data_content = None
    
    for segment in segments:
        dl_start_index = segment.find('DL')
        id_start_index = segment.find('ID')

        if dl_start_index != -1 or id_start_index != -1:
            z_pos = segment.find('Z')
            if z_pos != -1 and z_pos + 1 < len(segment):
                # å®é™…æ•°æ®å†…å®¹ä» 'Z' ä¹‹åå¼€å§‹ (è·³è¿‡ç´¢å¼•)
                main_data_content = segment[z_pos + 1:] 
                break
            
    if not main_data_content:
        return {"Error": "æœªæ‰¾åˆ° DL/ID ä¸»æ•°æ®æ®µçš„èµ·å§‹æ ‡è®°ï¼ˆZæ ‡è®°ç¼ºå¤±æˆ–æ•°æ®ä¸å®Œæ•´ï¼‰ã€‚"}
        
    # 3. æ”¶é›†æ‰€æœ‰å­—æ®µä»£ç åŠå…¶åœ¨æ•°æ®æµä¸­çš„èµ·å§‹ä½ç½® (Slicing Method)
    
    field_positions = []
    # ç¡®ä¿å­—æ®µä»£ç åˆ—è¡¨æŒ‰é•¿åº¦é™åºæ’åˆ—ï¼Œä»¥é¿å…çŸ­ä»£ç åŒ¹é…åˆ°é•¿ä»£ç çš„å‰ç¼€
    sorted_codes = sorted(fields_map.keys(), key=len, reverse=True)
    
    for code in sorted_codes:
        start = -1
        while True:
            # æŸ¥æ‰¾å­—æ®µä»£ç åœ¨æ•°æ®å†…å®¹ä¸­çš„ä½ç½®
            start = main_data_content.find(code, start + 1)
            if start == -1:
                break
            
            field_positions.append({'code': code, 'start_pos': start})

    if not field_positions:
        return {"Error": "å·²æ‰¾åˆ°ä¸»æ®µï¼Œä½†æœªèƒ½è¯†åˆ«ä»»ä½•æœ‰æ•ˆçš„ AAMVA å­—æ®µä»£ç ã€‚"}

    # 4. æŒ‰èµ·å§‹ä½ç½®æ’åº
    field_positions.sort(key=lambda x: x['start_pos'])

    # 5. æå–å€¼ (Value)
    for i in range(len(field_positions)):
        current = field_positions[i]
        
        # å½“å‰å­—æ®µçš„ä»£ç é•¿åº¦
        code_len = len(current['code'])
        
        # å½“å‰å€¼ä»å½“å‰ä»£ç çš„æœ«å°¾å¼€å§‹
        value_start = current['start_pos'] + code_len
        
        # å¯»æ‰¾ä¸‹ä¸€ä¸ªå­—æ®µä»£ç çš„èµ·å§‹ä½ç½®ä½œä¸ºå½“å‰å€¼çš„ç»“æŸ
        if i + 1 < len(field_positions):
            value_end = field_positions[i+1]['start_pos']
        else:
            # å¦‚æœæ˜¯æœ€åä¸€ä¸ªå­—æ®µï¼Œå–åˆ°å­—ç¬¦ä¸²æœ«å°¾
            value_end = len(main_data_content)
        
        # æå–å€¼å¹¶æ¸…ç†åˆ†éš”ç¬¦
        value = main_data_content[value_start:value_end].replace('\n', '').replace('\r', '').strip()
        
        description = fields_map.get(current['code'], current['code'])
        parsed_data[description] = value

    if not parsed_data:
        return {"Error": "å·²æ‰¾åˆ°ä¸»æ®µï¼Œä½†æœªèƒ½æå–ä»»ä½•æœ‰æ•ˆå­—æ®µã€‚"}
            
    return parsed_data

# ==================== 2. ç½‘é¡µç•Œé¢åŒº ====================

st.title("ğŸ’³ PDF417 æ‰«ç ä¸“å®¶")

# ä½¿ç”¨ tabs è¿›è¡Œæ¨¡å¼åˆ‡æ¢
tab1, tab2 = st.tabs(["ğŸ“¸ ç½‘é¡µå°çª— (å¿«é€Ÿ)", "ğŸ“± å…¨å±æ‹ç…§ (é«˜æ¸…æ¨è)"])

target_image = None
raw_data = None
data_source = None

# --- Tab 1: ç½‘é¡µç›¸æœº ---
with tab1:
    st.caption("é€‚ç”¨äºå…‰çº¿å¥½ã€æ¡ç æ¸…æ™°çš„ç®€å•åœºæ™¯ã€‚è¯·æ¨ªå±ä½¿ç”¨ã€‚")
    camera_file = st.camera_input("è¯·å¯¹å‡†æ¡ç ", label_visibility="collapsed")
    if camera_file:
        file_bytes = np.asarray(bytearray(camera_file.read()), dtype=np.uint8)
        target_image = cv2.imdecode(file_bytes, 1)
        data_source = "ç½‘é¡µç›¸æœº"

# --- Tab 2: å…¨å±æ‹ç…§ ---
with tab2:
    st.markdown("""
        <div style="background-color: #e8f5e9; padding: 15px; border-radius: 10px; border-left: 5px solid #4caf50; margin-bottom: 20px;">
            <h4 style="margin: 0; color: #2e7d32; font-size: 1.1rem;">ğŸš€ æœ€ä½³è¯†åˆ«æ–¹æ¡ˆï¼š</h4>
            <p style="margin: 10px 0 0 0; font-size: 1rem; color: #333;">
                ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œåœ¨å¼¹å‡ºçš„èœå•ä¸­é€‰æ‹© <b>â€œæ‹ç…§â€</b> æˆ– <b>â€œç›¸æœºâ€</b>ã€‚<br>
                è¿™å°†å¯åŠ¨ä½ çš„<b>ç³»ç»ŸåŸç”Ÿç›¸æœº</b>ï¼Œäº«å—<b>å…¨å±ã€é«˜æ¸…ã€æ‰‹åŠ¨å¯¹ç„¦</b>ä½“éªŒï¼
            </p>
        </div>
    """, unsafe_allow_html=True)

    upload_file = st.file_uploader("å¯åŠ¨å…¨å±ç›¸æœº", type=["jpg", "png", "jpeg", "heic"], label_visibility="collapsed")
    
    if upload_file:
        with st.spinner("æ­£åœ¨ä¸Šä¼ é«˜æ¸…åŸå›¾å¹¶è§£ç ..."):
            file_bytes = np.asarray(bytearray(upload_file.read()), dtype=np.uint8)
            target_image = cv2.imdecode(file_bytes, 1)
            data_source = "æ–‡ä»¶ä¸Šä¼ "

# --- å¤„ç†ç»“æœå±•ç¤º ---
if target_image is not None:
    st.divider()
    result = smart_scan_logic(target_image)
    
    if result:
        st.success("ğŸ‰ è§£ç æˆåŠŸï¼")
        
        raw_data = result.bytes if result.bytes else result.text.encode('latin-1', errors='ignore')
        
        # ç¡®å®šæ•°æ®ç±»å‹
        data_type = "äºŒè¿›åˆ¶ (Bytes)" if isinstance(result.bytes, bytes) else "æ–‡æœ¬ (Text)"
        
        # 1. ç»“æœæ¦‚è§ˆ
        st.info(f"æ•°æ®ç±»å‹: **{data_type}** | å­—èŠ‚é•¿åº¦: **{len(raw_data)}** bytes")
        
        # 2. ç»“æ„åŒ–è§£æ
        if len(raw_data) > 100:
            st.subheader("ğŸ“‹ ç»“æ„åŒ–æ•°æ®è§£æ (AAMVA)")
            parsed_data = parse_aamva_data(raw_data)
            
            if "Error" in parsed_data:
                 st.error(f"è§£æå¤±è´¥: {parsed_data['Error']}")
            else:
                 # ä½¿ç”¨ Pandas DataFrame å±•ç¤ºè§£æç»“æœ
                 df_parsed = pd.DataFrame(parsed_data.items(), columns=["å­—æ®µ", "å€¼"])
                 
                 # ç¡®ä¿è®¸å¯è¯å·å’Œå§“åæ”¾åœ¨æœ€å‰é¢
                 def sort_key(column):
                    order = {'é©¾ç…§/è¯ä»¶å·ç  (License No.)': 0, 'å§“æ° (Last Name)': 1, 'å (First Name)': 2}
                    return column.map(lambda x: order.get(x, 99))
                     
                 df_parsed = df_parsed.sort_values(by="å­—æ®µ", key=sort_key, ascending=True, ignore_index=True)
                 
                 st.dataframe(df_parsed, use_container_width=True, hide_index=True)
                 
                 # --- å¿«é€ŸæŸ¥çœ‹ (è¯ä»¶å·) ---
                 license_no = parsed_data.get('é©¾ç…§/è¯ä»¶å·ç  (License No.)', 'N/A')
                 st.markdown(f"**å¿«é€ŸæŸ¥çœ‹ (è¯ä»¶å·):** **`{license_no}`** å¯¹åº” **é©¾ç…§/è¯ä»¶å·ç **")

        # 3. HEX æ•°æ®
        with st.expander("æŸ¥çœ‹åº•å±‚ HEX æ•°æ® (ç‚¹å‡»å±•å¼€)", expanded=False):
            hex_str = get_hex_dump_str(raw_data)
            st.code(hex_str, language="text")

        # 4. å‚æ•°é€†å‘è®¡ç®—å™¨ (å«å¯¼å‡º CSV)
        st.subheader("ğŸ“ PDF417 å‚æ•°é€†å‘è®¡ç®— (AAMVA)")
        byte_len = len(raw_data)
        df_params = calculate_pdf417_params(byte_len)
        
        col_summary, col_table_content = st.columns([1, 2])

        with col_summary:
            st.markdown(f"**åˆ†æé•¿åº¦:** `{byte_len} bytes`")
            st.markdown(f"**ECC å®‰å…¨ç­‰çº§:** `Level 5 (64 Codewords)`")
            
            best_row = df_params[df_params['åˆ—æ•° (Cols)'] == 17]
            if not best_row.empty:
                rec_rows = best_row.iloc[0]['æ¨ç®—è¡Œæ•° (Rows)']
                st.success(f"ğŸ’¡ AAMVA æ¨è: **Cols=17, Rows={rec_rows}**")

        with col_table_content:
            col_header, col_button = st.columns([4, 1])
            
            with col_header:
                st.markdown("##### æ¨ç®—è¡Œåˆ—ç»„åˆç»“æœ (æ•°æ®è¡¨)")

            with col_button:
                csv_data = df_params.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ’¾ å¯¼å‡º CSV",
                    data=csv_data,
                    file_name='pdf417_params.csv',
                    mime='text/csv',
                    help="ç‚¹å‡»ä¸‹è½½è¡¨æ ¼æ•°æ®ä¸º CSV æ–‡ä»¶ï¼Œæ–¹ä¾¿å¤åˆ¶åˆ°å…¶ä»–åœ°æ–¹ã€‚"
                )
            
            st.dataframe(
                df_params,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "ä¼°ç®—å®½é«˜æ¯” (W/H)": st.column_config.TextColumn("W/H æ¯”ä¾‹"),
                    "ç±»å‹å¤‡æ³¨": st.column_config.TextColumn("å¤‡æ³¨"),
                }
            )

        # 5. é‡å¼€æŒ‰é’®
        st.divider()
        if st.button("ğŸ”„ æ‰«æä¸‹ä¸€å¼ ", type="primary"):
            st.rerun()
